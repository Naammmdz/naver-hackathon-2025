# PhÃ¢n tÃ­ch Code Backend AI Service

## ğŸ“‹ Tá»•ng quan

**Backend AI Service** lÃ  má»™t há»‡ thá»‘ng RAG (Retrieval-Augmented Generation) Ä‘Æ°á»£c xÃ¢y dá»±ng báº±ng Python, sá»­ dá»¥ng FastAPI Ä‘á»ƒ cung cáº¥p REST API cho viá»‡c quáº£n lÃ½ documents vÃ  tráº£ lá»i cÃ¢u há»i dá»±a trÃªn documents.

### ThÃ´ng tin cÆ¡ báº£n:
- **Framework**: FastAPI
- **Database**: PostgreSQL vá»›i pgvector extension
- **Architecture Pattern**: Layered Architecture + Factory Pattern
- **AI Framework**: LangGraph, LangChain
- **Vector Search**: pgvector (PostgreSQL native)

---

## ğŸ—ï¸ Kiáº¿n trÃºc tá»•ng thá»ƒ

### 1. Cáº¥u trÃºc thÆ° má»¥c

```
backend-ai-service/
â”œâ”€â”€ api/                    # FastAPI application layer
â”‚   â”œâ”€â”€ main.py            # Entry point, app configuration
â”‚   â””â”€â”€ routes/            # API endpoints
â”‚       â”œâ”€â”€ health.py      # Health check endpoints
â”‚       â”œâ”€â”€ workspaces.py  # Workspace management
â”‚       â”œâ”€â”€ documents.py   # Document management
â”‚       â””â”€â”€ query.py       # RAG query endpoints
â”‚
â”œâ”€â”€ agents/                # AI Agent layer
â”‚   â”œâ”€â”€ document_agent.py # Main RAG agent
â”‚   â”œâ”€â”€ graphs/           # LangGraph workflows
â”‚   â”‚   â””â”€â”€ document_graph/
â”‚   â”‚       â”œâ”€â”€ nodes.py  # Workflow nodes
â”‚   â”‚       â”œâ”€â”€ edges.py  # Workflow edges
â”‚   â”‚       â””â”€â”€ state.py  # State management
â”‚   â”œâ”€â”€ memory/           # Memory management
â”‚   â”‚   â”œâ”€â”€ conversation_memory.py
â”‚   â”‚   â”œâ”€â”€ fact_extractor.py
â”‚   â”‚   â””â”€â”€ memory_retrieval.py
â”‚   â”œâ”€â”€ tools/            # Agent tools
â”‚   â”‚   â””â”€â”€ retrieval/   # Retrieval tools
â”‚   â”‚       â”œâ”€â”€ vector_similarity/
â”‚   â”‚       â”œâ”€â”€ bm25/
â”‚   â”‚       â”œâ”€â”€ hybrid/
â”‚   â”‚       â””â”€â”€ reranking/
â”‚   â””â”€â”€ prompts/          # Prompt templates
â”‚
â”œâ”€â”€ database/             # Data access layer
â”‚   â”œâ”€â”€ connection.py     # DB connection & pooling
â”‚   â”œâ”€â”€ models/           # SQLAlchemy models
â”‚   â”‚   â”œâ”€â”€ base.py
â”‚   â”‚   â”œâ”€â”€ workspace.py
â”‚   â”‚   â”œâ”€â”€ document.py
â”‚   â”‚   â””â”€â”€ ai_models.py  # RAG-specific models
â”‚   â”œâ”€â”€ repositories/     # Repository pattern
â”‚   â”‚   â”œâ”€â”€ base.py
â”‚   â”‚   â”œâ”€â”€ workspace.py
â”‚   â”‚   â”œâ”€â”€ document.py
â”‚   â”‚   â””â”€â”€ ai_repository.py
â”‚   â””â”€â”€ migrations/       # Database migrations
â”‚
â”œâ”€â”€ data_preprocessing/    # Document processing pipeline
â”‚   â”œâ”€â”€ parsing/          # Document parsers
â”‚   â”‚   â”œâ”€â”€ parser_factory.py
â”‚   â”‚   â”œâ”€â”€ docling_parser.py
â”‚   â”‚   â””â”€â”€ markdown_parser.py
â”‚   â”œâ”€â”€ chunking/         # Text chunking strategies
â”‚   â”‚   â”œâ”€â”€ chunker_factory.py
â”‚   â”‚   â”œâ”€â”€ paragraph_chunker.py
â”‚   â”‚   â”œâ”€â”€ fixed_size_chunker.py
â”‚   â”‚   â”œâ”€â”€ semantic_chunker.py
â”‚   â”‚   â””â”€â”€ hierarchical_chunker.py
â”‚   â””â”€â”€ embedding/       # Embedding generation
â”‚       â”œâ”€â”€ embedding_factory.py
â”‚       â”œâ”€â”€ huggingface_embedder.py
â”‚       â””â”€â”€ naver_embedder.py
â”‚
â”œâ”€â”€ llm/                  # LLM abstraction layer
â”‚   â”œâ”€â”€ llm_factory.py   # Factory for LLM providers
â”‚   â””â”€â”€ providers/       # LLM provider implementations
â”‚       â”œâ”€â”€ clova.py     # Naver HyperCLOVA X
â”‚       â”œâ”€â”€ openai.py    # OpenAI GPT
â”‚       â”œâ”€â”€ cerebras.py  # Cerebras
â”‚       â””â”€â”€ gemini.py    # Google Gemini
â”‚
â”œâ”€â”€ scripts/              # Utility scripts
â”‚   â””â”€â”€ ingest_documents.py
â”‚
â””â”€â”€ utils/                # Utilities
    â””â”€â”€ logger.py
```

---

## ğŸ”‘ CÃ¡c thÃ nh pháº§n chÃ­nh

### 1. API Layer (`api/`)

#### FastAPI Application (`api/main.py`)
- **Chá»©c nÄƒng**: Entry point cá»§a á»©ng dá»¥ng
- **TÃ­nh nÄƒng**:
  - CORS middleware cho cross-origin requests
  - Lifespan management (startup/shutdown)
  - Router registration vá»›i prefix `/api/v1`
  - Auto-generated API documentation (Swagger/ReDoc)

#### API Routes:
1. **Health Routes** (`health.py`):
   - `/health` - Health check vá»›i database vÃ  LLM status
   - `/ready` - Readiness check
   - `/liveness` - Liveness probe

2. **Workspace Routes** (`workspaces.py`):
   - CRUD operations cho workspaces
   - Workspace isolation cho documents

3. **Document Routes** (`documents.py`):
   - Upload vÃ  ingest documents
   - List, get, delete documents
   - Document statistics

4. **Query Routes** (`query.py`):
   - RAG query endpoint
   - Session management
   - Conversation history

---

### 2. Agent Layer (`agents/`)

#### Document Agent (`document_agent.py`)
**Kiáº¿n trÃºc**: LangGraph workflow

**Workflow Steps**:
1. **Query Reformulation**: Chuyá»ƒn Ä‘á»•i cÃ¢u há»i follow-up thÃ nh standalone question
2. **Retrieval**: Hybrid search (vector + BM25)
3. **Reranking**: Sáº¯p xáº¿p láº¡i káº¿t quáº£ theo relevance
4. **Generation**: Táº¡o cÃ¢u tráº£ lá»i vá»›i citations
5. **Fallback**: Xá»­ lÃ½ khi khÃ´ng tÃ¬m tháº¥y relevant documents

**Features**:
- Multi-step reasoning vá»›i LangGraph
- Conversation memory integration
- Citation extraction
- Confidence scoring

#### Graph Nodes (`agents/graphs/document_graph/nodes.py`)
- `reformulate_query_node`: Reformulate queries vá»›i context
- `retrieve_node`: Hybrid search
- `rerank_node`: Relevance reranking
- `generate_answer_node`: LLM generation vá»›i citations
- `fallback_node`: Handle no results case

#### Memory System (`agents/memory/`)
- **Conversation Memory**: Short-term memory cho conversations
- **Fact Extractor**: Extract facts tá»« Q&A pairs
- **Memory Retrieval**: Retrieve relevant context tá»« memory

#### Retrieval Tools (`agents/tools/retrieval/`)
- **Vector Similarity Search**: Semantic search vá»›i embeddings
- **BM25 Search**: Keyword-based search (disabled by default)
- **Hybrid Search**: Káº¿t há»£p vector + BM25
- **Reranker**: Cross-encoder reranking model

---

### 3. Data Access Layer (`database/`)

#### Database Connection (`connection.py`)
- **Connection Pooling**: QueuePool vá»›i 10 connections, max 20 overflow
- **Session Management**: Context manager pattern
- **Connection Health**: Pool pre-ping, auto-recycle

#### Models (`database/models/`)
**Core Models**:
- `Workspace`: Workspace isolation
- `Document`: Document metadata
- `Task`: Task management (from core service)

**AI Models** (`ai_models.py`):
- `DocumentChunk`: Chunks vá»›i vector embeddings (1024-dim)
- `Conversation`: Chat history
- `LongTermMemory`: Learned knowledge
- `AgentAction`: Agent action logs
- `HITLFeedback`: Human-in-the-loop feedback

#### Repository Pattern (`database/repositories/`)
- **BaseRepository**: Generic CRUD operations
- **Specialized Repositories**:
  - `DocumentChunkRepository`: Vector search queries
  - `ConversationRepository`: Session management
  - `LongTermMemoryRepository`: Memory retrieval
  - `AgentActionRepository`: Action logging

---

### 4. Data Preprocessing Pipeline (`data_preprocessing/`)

#### Document Parsing (`parsing/`)
**Parser Factory Pattern**:
- **DoclingParser**: Universal parser (PDF, DOCX, PPTX, images)
  - OCR support
  - Table extraction
  - Markdown output
- **MarkdownParser**: Markdown-specific parsing
  - Frontmatter extraction
  - Code blocks
  - Tables

#### Text Chunking (`chunking/`)
**Chunking Strategies**:
1. **Paragraph Chunker** (default): Chunk theo paragraphs
2. **Fixed Size Chunker**: Fixed-size chunks vá»›i overlap
3. **Semantic Chunker**: Chunk dá»±a trÃªn semantic similarity
4. **Hierarchical Chunker**: Multi-level chunking

**Configuration**:
- Chunk size: 2000 chars
- Overlap: 50 chars
- Method: paragraph (configurable)

#### Embedding Generation (`embedding/`)
**Embedding Providers**:
- **Naver Embedder** (default): `bge-m3` model (1024 dimensions)
- **HuggingFace Embedder**: `Qwen/Qwen3-Embedding-0.6B`

**Features**:
- Batch processing
- Configurable batch size
- Model metadata tracking

---

### 5. LLM Layer (`llm/`)

#### LLM Factory (`llm_factory.py`)
**Factory Pattern** cho multi-provider support:

**Supported Providers**:
1. **Naver HyperCLOVA X** (default)
   - Model: HCX-007
   - Vietnamese language support
2. **OpenAI**
   - Model: gpt-4o-mini
3. **Cerebras**
   - Model: qwen-3-32b
4. **Google Gemini**
   - Model: gemini-2.0-flash-lite

**Features**:
- Structured output support
- Token counting
- Provider abstraction
- Config-based initialization

---

## ğŸ”„ Data Flow

### Document Ingestion Flow:
```
1. Upload Document (API)
   â†“
2. Parse Document (DoclingParser/MarkdownParser)
   â†“
3. Chunk Text (Paragraph/Fixed/Semantic Chunker)
   â†“
4. Generate Embeddings (Naver/HuggingFace Embedder)
   â†“
5. Store in Database
   - Document record
   - DocumentChunk records vá»›i embeddings
```

### Query Flow (RAG):
```
1. User Query (API)
   â†“
2. Query Reformulation (náº¿u cÃ³ conversation history)
   â†“
3. Hybrid Retrieval
   - Vector similarity search
   - BM25 search (optional)
   - Combine results
   â†“
4. Reranking
   - Cross-encoder reranker
   â†“
5. Context Retrieval
   - Conversation memory
   - Long-term memory
   â†“
6. LLM Generation
   - Prompt vá»›i retrieved chunks
   - Generate answer vá»›i citations
   â†“
7. Store Conversation
   - User question
   - Assistant answer
   - Extract facts
```

---

## ğŸ¯ Design Patterns

### 1. Factory Pattern
- **LLM Factory**: Táº¡o LLM instances tá»« multiple providers
- **Parser Factory**: Táº¡o parsers dá»±a trÃªn file type
- **Chunker Factory**: Táº¡o chunkers dá»±a trÃªn strategy
- **Embedding Factory**: Táº¡o embedders dá»±a trÃªn provider

### 2. Repository Pattern
- **BaseRepository**: Generic CRUD operations
- **Specialized Repositories**: Domain-specific queries
- **Abstraction**: TÃ¡ch biá»‡t data access logic

### 3. Strategy Pattern
- **Chunking Strategies**: Multiple chunking algorithms
- **Retrieval Strategies**: Vector, BM25, Hybrid
- **LLM Providers**: Swappable LLM backends

### 4. Workflow Pattern (LangGraph)
- **State-based workflow**: DocumentGraphState
- **Node-based processing**: Má»—i node lÃ  má»™t step
- **Conditional routing**: Dá»±a trÃªn state

---

## ğŸ”§ Configuration

### Config File (`config.yml`)
**Sections**:
1. **Data Preprocessing**:
   - Parsing config (OCR, table extraction)
   - Chunking config (method, size, overlap)
   - Embedding config (provider, model, batch size)

2. **LLM**:
   - Default provider
   - Provider-specific configs
   - Model, temperature, max_tokens

3. **Retrieval**:
   - Vector similarity settings
   - BM25 settings (disabled by default)
   - Reranker config

### Environment Variables (`.env`)
- `NEONDB`: PostgreSQL connection string
- `NAVER_CLIENT_ID`: Naver API credentials
- `NAVER_CLIENT_SECRET`: Naver API credentials
- `OPENAI_API_KEY`: OpenAI API key
- `GOOGLE_API_KEY`: Google API key
- `CEREBRAS_API_KEY`: Cerebras API key

---

## ğŸ“Š Database Schema

### Core Tables:
- `workspaces`: Workspace isolation
- `documents`: Document metadata
- `tasks`: Task management

### RAG Tables:
- `document_chunks`: 
  - Vector embeddings (pgvector)
  - Chunk text vÃ  metadata
  - Indexes cho fast retrieval
  
- `conversations`:
  - Chat history
  - Session management
  - Confidence scores
  
- `long_term_memory`:
  - Learned knowledge
  - Confidence tracking
  - Access patterns
  
- `agent_actions`:
  - Action logging
  - Debugging support
  
- `hitl_feedback`:
  - Human feedback
  - Quality improvement

---

## ğŸš€ Key Features

### 1. Multi-Provider Support
- **LLM**: 4 providers (Naver, OpenAI, Cerebras, Gemini)
- **Embedding**: 2 providers (Naver, HuggingFace)
- **Easy switching**: Config-based

### 2. Advanced Retrieval
- **Hybrid Search**: Vector + BM25
- **Reranking**: Cross-encoder model
- **Multi-strategy**: Configurable

### 3. Memory System
- **Short-term**: Conversation history
- **Long-term**: Learned facts
- **Context-aware**: Query reformulation

### 4. Document Processing
- **Universal Parser**: Docling (PDF, DOCX, PPTX, images)
- **Multiple Chunking**: 4 strategies
- **Vietnamese Support**: underthesea tokenizer

### 5. Production Ready
- **Connection Pooling**: Database optimization
- **Error Handling**: Comprehensive error handling
- **Logging**: Structured logging
- **Health Checks**: Monitoring endpoints

---

## ğŸ” Code Quality

### Strengths:
âœ… **Clean Architecture**: Clear separation of concerns
âœ… **Design Patterns**: Factory, Repository, Strategy
âœ… **Type Safety**: Type hints throughout
âœ… **Documentation**: Docstrings vÃ  comments
âœ… **Modularity**: Easy to extend
âœ… **Configuration**: YAML-based config
âœ… **Error Handling**: Try-catch blocks
âœ… **Logging**: Structured logging

### Areas for Improvement:
âš ï¸ **Testing**: No test files visible
âš ï¸ **Validation**: Could use Pydantic models more extensively
âš ï¸ **Async**: Some operations could be async
âš ï¸ **Caching**: No caching layer visible
âš ï¸ **Rate Limiting**: No rate limiting
âš ï¸ **Authentication**: No auth middleware

---

## ğŸ“ˆ Performance Considerations

### Optimizations:
1. **Connection Pooling**: Database connections reused
2. **Batch Processing**: Embeddings generated in batches
3. **Vector Indexes**: pgvector indexes for fast search
4. **Query Optimization**: Indexed columns

### Potential Bottlenecks:
1. **Embedding Generation**: CPU/GPU intensive
2. **LLM Calls**: Network latency
3. **Vector Search**: Large datasets
4. **Document Parsing**: Large files

---

## ğŸ” Security Considerations

### Current State:
- âœ… CORS configured
- âœ… SQL injection protection (SQLAlchemy ORM)
- âš ï¸ No authentication
- âš ï¸ No rate limiting
- âš ï¸ API keys in environment (good)

### Recommendations:
- Add authentication middleware
- Implement rate limiting
- Add input validation
- Sanitize file uploads
- Add audit logging

---

## ğŸ“ Dependencies

### Core:
- FastAPI: Web framework
- SQLAlchemy: ORM
- pgvector: Vector search
- LangGraph: Agent workflows
- LangChain: LLM abstraction

### AI/ML:
- sentence-transformers: Embeddings
- transformers: HuggingFace models
- docling: Document parsing
- underthesea: Vietnamese NLP

### LLM Providers:
- langchain-naver
- langchain-openai
- langchain-cerebras
- langchain-google-genai

---

## ğŸ“ Learning Points

1. **RAG Architecture**: Complete RAG pipeline implementation
2. **LangGraph**: State-based agent workflows
3. **Vector Search**: pgvector integration
4. **Multi-Provider**: Abstraction pattern
5. **Factory Pattern**: Extensibility
6. **Repository Pattern**: Data access abstraction

---

## ğŸ“š TÃ i liá»‡u tham kháº£o

- API Documentation: http://localhost:8000/docs
- Code structure: Xem cÃ¡c file README trong tá»«ng module
- Config: `config.yml`
- Setup: `README_SETUP.md`, `QUICKSTART.md`

---

## ğŸ”„ Workflow Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Client    â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚ HTTP Request
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  FastAPI Routes â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Document Agent  â”‚
â”‚  (LangGraph)    â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â”œâ”€â”€â–º Retrieval â”€â”€â–º Vector Search â”€â”€â–º Database
       â”‚
       â”œâ”€â”€â–º Reranking â”€â”€â–º Cross-encoder
       â”‚
       â”œâ”€â”€â–º Memory â”€â”€â–º Conversation/Long-term
       â”‚
       â””â”€â”€â–º Generation â”€â”€â–º LLM â”€â”€â–º Answer + Citations
```

---

**TÃ³m láº¡i**: ÄÃ¢y lÃ  má»™t há»‡ thá»‘ng RAG Ä‘Æ°á»£c thiáº¿t káº¿ tá»‘t vá»›i kiáº¿n trÃºc rÃµ rÃ ng, há»— trá»£ multi-provider, vÃ  cÃ³ kháº£ nÄƒng má»Ÿ rá»™ng cao. Code quality tá»‘t vá»›i viá»‡c sá»­ dá»¥ng design patterns phÃ¹ há»£p.

