# LLM Module - Multi-Provider Support vá»›i Structured Output

Module LLM há»— trá»£ nhiá»u providers khÃ¡c nhau vá»›i kháº£ nÄƒng structured output (trÃ­ch xuáº¥t dá»¯ liá»‡u cÃ³ cáº¥u trÃºc).

## ğŸš€ Providers Ä‘Æ°á»£c há»— trá»£

- âœ… **Naver HyperCLOVA X** - Model tiáº¿ng Viá»‡t máº¡nh máº½
- âœ… **OpenAI** - GPT-4o, GPT-4o-mini, GPT-3.5-turbo
- âœ… **Cerebras** - Llama 3.1 vá»›i tá»‘c Ä‘á»™ cá»±c nhanh
- âœ… **Google Gemini** - Gemini 1.5 Flash/Pro

## ğŸ“¦ CÃ i Ä‘áº·t

```bash
pip install -r requirements.txt
```

## ğŸ”‘ Cáº¥u hÃ¬nh API Keys

Táº¡o file `.env` vá»›i cÃ¡c API keys:

```properties
# Naver HyperCLOVA X
CLOVASTUDIO_API_KEY=your_naver_api_key

# OpenAI
OPENAI_API_KEY=your_openai_api_key

# Cerebras
CEREBRAS_API_KEY=your_cerebras_api_key

# Google Gemini
GEMINI_API_KEY=your_gemini_api_key
```

## âš™ï¸ Cáº¥u hÃ¬nh Models

Chá»‰nh sá»­a `config.yml` Ä‘á»ƒ cáº¥u hÃ¬nh cÃ¡c models:

```yaml
llm:
  default_provider: "naver"
  
  providers:
    naver:
      model: "HCX-007"
      temperature: 0.1
      max_tokens: 2000
      system_prompt: "Báº¡n lÃ  má»™t trá»£ lÃ½ AI..."
    
    openai:
      model: "gpt-4o-mini"
      temperature: 0.1
      max_tokens: 2000
      system_prompt: "You are a helpful assistant..."
```

## ğŸ’» Sá»­ dá»¥ng

### 1. Sá»­ dá»¥ng cÆ¡ báº£n

```python
from llm import LLMFactory
from langchain_core.messages import HumanMessage

# Khá»Ÿi táº¡o factory
factory = LLMFactory()

# Táº¡o LLM vá»›i provider máº·c Ä‘á»‹nh (Naver)
llm = factory.create_llm()

# Hoáº·c chá»n provider cá»¥ thá»ƒ
llm_openai = factory.create_llm("openai")
llm_cerebras = factory.create_llm("cerebras")
llm_gemini = factory.create_llm("gemini")

# Sá»­ dá»¥ng
response = llm.invoke([HumanMessage(content="Hello!")])
print(response.content)
```

### 2. Structured Output (TrÃ­ch xuáº¥t dá»¯ liá»‡u cÃ³ cáº¥u trÃºc)

```python
from llm import LLMFactory
from pydantic import BaseModel, Field
from typing import List
from langchain_core.messages import HumanMessage, SystemMessage

# Äá»‹nh nghÄ©a schema vá»›i Pydantic
class Person(BaseModel):
    """ThÃ´ng tin vá» má»™t ngÆ°á»i"""
    name: str = Field(description="TÃªn Ä‘áº§y Ä‘á»§")
    age: int = Field(description="Tuá»•i")
    occupation: str = Field(description="Nghá» nghiá»‡p")

class PeopleList(BaseModel):
    """Danh sÃ¡ch ngÆ°á»i"""
    people: List[Person] = Field(description="Danh sÃ¡ch cÃ¡c ngÆ°á»i")
    total: int = Field(description="Tá»•ng sá»‘ ngÆ°á»i")

# Khá»Ÿi táº¡o
factory = LLMFactory()

# Táº¡o structured LLM
llm = factory.create_structured_llm(
    schema=PeopleList,
    provider="naver"  # hoáº·c "openai", "cerebras", "gemini"
)

# Sá»­ dá»¥ng
text = "John lÃ  ká»¹ sÆ° 30 tuá»•i. Mary lÃ  bÃ¡c sÄ© 28 tuá»•i."
messages = [
    SystemMessage(content="Báº¡n lÃ  trá»£ lÃ½ AI."),
    HumanMessage(content=f"TrÃ­ch xuáº¥t thÃ´ng tin tá»«: {text}")
]

result = llm.invoke(messages)

# Truy cáº­p dá»¯ liá»‡u structured
print(f"Tá»•ng sá»‘ ngÆ°á»i: {result.total}")
for person in result.people:
    print(f"- {person.name}, {person.age} tuá»•i, nghá» {person.occupation}")
```

### 3. So sÃ¡nh nhiá»u Providers

```python
from llm import LLMFactory

factory = LLMFactory()

# Test cÃ¹ng má»™t schema vá»›i nhiá»u providers
providers = ["naver", "openai", "cerebras", "gemini"]

for provider in providers:
    try:
        llm = factory.create_structured_llm(MySchema, provider)
        result = llm.invoke(messages)
        print(f"{provider}: {result}")
    except Exception as e:
        print(f"{provider} failed: {e}")
```

### 4. Kiá»ƒm tra Providers cÃ³ sáºµn

```python
from llm import LLMFactory

factory = LLMFactory()

# Liá»‡t kÃª táº¥t cáº£ providers
factory.list_providers()

# Kiá»ƒm tra providers cÃ³ API key
available = factory.get_available_providers()
print(available)
# {'naver': True, 'openai': True, 'cerebras': False, 'gemini': True}
```

### 5. Override Configuration

```python
from llm import LLMFactory

factory = LLMFactory()

# Override model vÃ  temperature
llm = factory.create_llm(
    provider="openai",
    model="gpt-4o",  # Thay vÃ¬ gpt-4o-mini
    temperature=0.5,  # Thay vÃ¬ 0.1
    max_tokens=4000
)
```

## ğŸ¯ VÃ­ dá»¥ thá»±c táº¿

### TrÃ­ch xuáº¥t thÃ´ng tin nhÃ¢n viÃªn

```python
from llm import LLMFactory
from pydantic import BaseModel, Field
from typing import List
from langchain_core.messages import HumanMessage

class Employee(BaseModel):
    name: str = Field(description="TÃªn nhÃ¢n viÃªn")
    position: str = Field(description="Chá»©c vá»¥")
    experience_years: int = Field(description="Sá»‘ nÄƒm kinh nghiá»‡m")

class EmployeeList(BaseModel):
    employees: List[Employee] = Field(description="Danh sÃ¡ch nhÃ¢n viÃªn")
    count: int = Field(description="Tá»•ng sá»‘ nhÃ¢n viÃªn")

# Khá»Ÿi táº¡o
factory = LLMFactory()
llm = factory.create_structured_llm(EmployeeList, "naver")

# Text cáº§n trÃ­ch xuáº¥t
text = """
CÃ´ng ty vá»«a tuyá»ƒn anh Nguyá»…n VÄƒn A, 5 nÄƒm kinh nghiá»‡m lÃ m Backend Developer.
Chá»‹ Tráº§n Thá»‹ B, 10 nÄƒm kinh nghiá»‡m, lÃ  Project Manager.
"""

# TrÃ­ch xuáº¥t
result = llm.invoke([HumanMessage(content=f"TrÃ­ch xuáº¥t: {text}")])

# Sá»­ dá»¥ng káº¿t quáº£
import json
print(json.dumps(result.model_dump(), indent=2, ensure_ascii=False))
```

### PhÃ¢n tÃ­ch cáº£m xÃºc

```python
from enum import Enum

class Sentiment(str, Enum):
    POSITIVE = "positive"
    NEGATIVE = "negative"
    NEUTRAL = "neutral"

class SentimentAnalysis(BaseModel):
    text: str = Field(description="Text gá»‘c")
    sentiment: Sentiment = Field(description="Cáº£m xÃºc")
    confidence: float = Field(description="Äá»™ tin cáº­y (0-1)")
    reason: str = Field(description="LÃ½ do phÃ¢n tÃ­ch")

factory = LLMFactory()
llm = factory.create_structured_llm(SentimentAnalysis, "openai")

result = llm.invoke([
    HumanMessage(content="PhÃ¢n tÃ­ch: Sáº£n pháº©m tuyá»‡t vá»i, tÃ´i ráº¥t hÃ i lÃ²ng!")
])

print(f"Cáº£m xÃºc: {result.sentiment}")
print(f"Äá»™ tin cáº­y: {result.confidence}")
print(f"LÃ½ do: {result.reason}")
```

## ğŸ§ª Testing

Cháº¡y demo Ä‘á»ƒ test táº¥t cáº£ providers:

```bash
python demo_llm_factory.py
```

Test má»™t provider cá»¥ thá»ƒ:

```bash
python test_naver_quick.py
```

Test vá»›i file test.py gá»‘c:

```bash
python test.py
```

## ğŸ“ Cáº¥u trÃºc thÆ° má»¥c

```
llm/
â”œâ”€â”€ __init__.py              # Module exports
â”œâ”€â”€ llm_factory.py           # Factory chÃ­nh
â””â”€â”€ providers/
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ clova.py            # Naver HyperCLOVA X
    â”œâ”€â”€ openai.py           # OpenAI GPT models
    â”œâ”€â”€ cerebras.py         # Cerebras Llama models
    â””â”€â”€ gemini.py           # Google Gemini
```

## ğŸ”§ API Reference

### LLMFactory

#### Methods:

- `create_llm(provider, **kwargs)` - Táº¡o LLM instance
- `create_structured_llm(schema, provider, **kwargs)` - Táº¡o structured LLM
- `create_provider(provider, **kwargs)` - Táº¡o provider instance
- `get_available_providers()` - Danh sÃ¡ch providers cÃ³ sáºµn
- `list_providers()` - In thÃ´ng tin táº¥t cáº£ providers
- `get_system_prompt(provider)` - Láº¥y system prompt cá»§a provider

### Provider Classes

Má»—i provider (ClovaProvider, OpenAIProvider, etc.) cÃ³:

- `__init__(model, temperature, max_tokens, api_key, **kwargs)` - Khá»Ÿi táº¡o
- `get_llm()` - Láº¥y base LLM
- `get_structured_llm(schema)` - Láº¥y structured LLM
- `get_config()` - Láº¥y cáº¥u hÃ¬nh hiá»‡n táº¡i
- `is_available()` - Kiá»ƒm tra provider cÃ³ sáºµn khÃ´ng (static method)

## âš ï¸ LÆ°u Ã½ quan trá»ng

### Naver HyperCLOVA X

- **Báº®T BUá»˜C** pháº£i cÃ³: `thinking={"effort": "none"}` vÃ  `disabled_params={"parallel_tool_calls": None}`
- API key Ä‘Æ°á»£c Ä‘á»c tá»« environment variable `CLOVASTUDIO_API_KEY`
- Pydantic fields **PHáº¢I** cÃ³ `description` Ä‘á»ƒ trÃ¡nh lá»—i API

### OpenAI

- Há»— trá»£ Ä‘áº§y Ä‘á»§ structured output vá»›i function calling
- Models: gpt-4o, gpt-4o-mini, gpt-3.5-turbo, etc.

### Cerebras

- Cá»±c nhanh cho inference
- Models: llama3.1-8b, llama3.1-70b

### Gemini

- Há»— trá»£ tá»‘t structured output
- Models: gemini-1.5-flash, gemini-1.5-pro, gemini-2.0-flash-lite

## ğŸ› Troubleshooting

### Lá»—i: "API key not found"

Kiá»ƒm tra file `.env` cÃ³ chá»©a API key Ä‘Ãºng format khÃ´ng.

### Lá»—i: "Invalid parameter: tools[].function.description" (Naver)

Äáº£m báº£o táº¥t cáº£ Pydantic Fields cÃ³ `description`:

```python
# âŒ Sai
class MyModel(BaseModel):
    name: str = Field()

# âœ… ÄÃºng
class MyModel(BaseModel):
    name: str = Field(description="TÃªn")
```

### Lá»—i: "model validation error"

Kiá»ƒm tra schema Pydantic cÃ³ há»£p lá»‡ khÃ´ng, Ä‘áº·c biá»‡t cÃ¡c type hints.

## ğŸ“„ License

MIT License

## ğŸ‘¥ Contributors

- Your Team

---

**Happy coding! ğŸ‰**
