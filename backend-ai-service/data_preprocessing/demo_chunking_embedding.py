"""
Demo: Chunking and Embedding

This script demonstrates how to use the chunking and embedding modules
to process documents for RAG (Retrieval-Augmented Generation).

Usage:
    python data_preprocessing/demo_chunking_embedding.py
"""

import os
import sys
from pathlib import Path

# Add parent directory to path
sys.path.insert(0, str(Path(__file__).parent.parent))

from data_preprocessing.chunking import ChunkerFactory
from data_preprocessing.embedding import EmbeddingFactory


def demo_chunking():
    """Demonstrate different chunking strategies"""
    
    print("=" * 80)
    print("DEMO: Text Chunking")
    print("=" * 80)
    
    # Sample text
    sample_text = """
Agentic AI l√† m·ªôt h·ªá th·ªëng tr√≠ tu·ªá nh√¢n t·∫°o c√≥ kh·∫£ nƒÉng t·ª± ch·ªß ra quy·∫øt ƒë·ªãnh v√† h√†nh ƒë·ªông 
ƒë·ªÉ ƒë·∫°t ƒë∆∞·ª£c m·ª•c ti√™u ƒë√£ ƒë·ªãnh. Kh√°c v·ªõi AI truy·ªÅn th·ªëng ch·ªâ ƒë∆°n thu·∫ßn x·ª≠ l√Ω d·ªØ li·ªáu ƒë·∫ßu v√†o 
v√† tr·∫£ v·ªÅ k·∫øt qu·∫£, Agentic AI c√≥ kh·∫£ nƒÉng l·∫≠p k·∫ø ho·∫°ch, suy lu·∫≠n v√† t∆∞∆°ng t√°c v·ªõi m√¥i tr∆∞·ªùng.

C√°c ƒë·∫∑c ƒëi·ªÉm ch√≠nh c·ªßa Agentic AI:

1. T·ª± ch·ªß (Autonomy): AI c√≥ th·ªÉ t·ª± ƒë∆∞a ra quy·∫øt ƒë·ªãnh m√† kh√¥ng c·∫ßn can thi·ªáp li√™n t·ª•c t·ª´ con ng∆∞·ªùi.

2. L·∫≠p k·∫ø ho·∫°ch (Planning): H·ªá th·ªëng c√≥ kh·∫£ nƒÉng ph√¢n t√≠ch v·∫•n ƒë·ªÅ ph·ª©c t·∫°p, chia nh·ªè th√†nh 
c√°c b∆∞·ªõc v√† l·∫≠p k·∫ø ho·∫°ch th·ª±c hi·ªán tu·∫ßn t·ª±.

3. S·ª≠ d·ª•ng c√¥ng c·ª• (Tool Use): AI c√≥ th·ªÉ s·ª≠ d·ª•ng c√°c c√¥ng c·ª• b√™n ngo√†i nh∆∞ t√¨m ki·∫øm web, 
truy v·∫•n database, g·ªçi API ƒë·ªÉ thu th·∫≠p th√¥ng tin c·∫ßn thi·∫øt.

4. B·ªô nh·ªõ (Memory): H·ªá th·ªëng ghi nh·ªõ ng·ªØ c·∫£nh v√† h·ªçc h·ªèi t·ª´ c√°c t∆∞∆°ng t√°c tr∆∞·ªõc ƒë√≥ ƒë·ªÉ 
c·∫£i thi·ªán hi·ªáu su·∫•t.

5. Ph·∫£n h·ªìi v√† ƒëi·ªÅu ch·ªânh (Feedback & Adaptation): AI c√≥ th·ªÉ ƒë√°nh gi√° k·∫øt qu·∫£ c·ªßa h√†nh ƒë·ªông 
v√† ƒëi·ªÅu ch·ªânh chi·∫øn l∆∞·ª£c khi c·∫ßn thi·∫øt.
"""
    
    print(f"\nSample text length: {len(sample_text)} characters")
    print("\n" + "-" * 80)
    
    # 1. Paragraph Chunker (RECOMMENDED)
    print("\n1. PARAGRAPH CHUNKER (Recommended)")
    print("-" * 80)
    
    para_chunker = ChunkerFactory.create_chunker(
        method="paragraph",
        chunk_size=300,
        overlap=50
    )
    
    para_chunks = para_chunker.chunk(sample_text)
    
    print(f"Generated {len(para_chunks)} chunks\n")
    for chunk in para_chunks:
        print(f"  {chunk}")
        print(f"  Preview: {chunk.text[:100]}...")
        print()
    
    # 2. Fixed-size Chunker
    print("\n2. FIXED-SIZE CHUNKER")
    print("-" * 80)
    
    fixed_chunker = ChunkerFactory.create_chunker(
        method="fixed",
        chunk_size=200,
        overlap=30
    )
    
    fixed_chunks = fixed_chunker.chunk(sample_text)
    
    print(f"Generated {len(fixed_chunks)} chunks\n")
    for i, chunk in enumerate(fixed_chunks[:3]):  # Show first 3
        print(f"  Chunk {i}: {len(chunk)} chars")
    
    # 3. From config
    print("\n3. FROM CONFIG FILE")
    print("-" * 80)
    
    try:
        config_chunker = ChunkerFactory.from_config()
        config_chunks = config_chunker.chunk(sample_text)
        print(f"Config method: {type(config_chunker).__name__}")
        print(f"Generated {len(config_chunks)} chunks")
    except Exception as e:
        print(f"Error loading from config: {e}")


def demo_embedding():
    """Demonstrate embedding generation"""
    
    print("\n\n" + "=" * 80)
    print("DEMO: Embedding Generation")
    print("=" * 80)
    
    # Sample texts
    texts = [
        "Agentic AI c√≥ kh·∫£ nƒÉng t·ª± ch·ªß ra quy·∫øt ƒë·ªãnh",
        "H·ªá th·ªëng AI n√†y c√≥ th·ªÉ l·∫≠p k·∫ø ho·∫°ch v√† suy lu·∫≠n",
        "Multi-agent systems work together to solve complex problems",
    ]
    
    print(f"\nSample texts ({len(texts)} texts):")
    for i, text in enumerate(texts):
        print(f"  {i+1}. {text}")
    
    # HuggingFace Embedder
    print("\n1. HUGGINGFACE EMBEDDER")
    print("-" * 80)
    
    try:
        hf_embedder = EmbeddingFactory.create_embedder(
            provider="huggingface",
            model_name="sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2",
            batch_size=8,
            device="cpu"
        )
        
        print(f"Model: {hf_embedder.model_name}")
        print(f"Loading model (this may take a while)...")
        
        result = hf_embedder.embed_batch(texts)
        
        print(f"\nEmbedding Results:")
        print(f"  - Number of embeddings: {len(result)}")
        print(f"  - Embedding dimensions: {result.dimensions}")
        print(f"  - Metadata: {result.metadata}")
        print(f"\nFirst embedding shape: {result.embeddings[0].shape}")
        print(f"First 10 values: {result.embeddings[0][:10]}")
        
    except ImportError:
        print("‚ö†Ô∏è  sentence-transformers not installed")
        print("   Install with: pip install sentence-transformers")
    except Exception as e:
        print(f"Error: {e}")
    
    # Naver Embedder
    print("\n\n2. NAVER CLOVA EMBEDDER")
    print("-" * 80)
    
    try:
        naver_embedder = EmbeddingFactory.create_embedder(
            provider="naver",
            model_name="clir-emb-dolphin"
        )
        result = naver_embedder.embed_batch(texts)
        print("Success!")
    except NotImplementedError as e:
        print(f"‚ö†Ô∏è  {e}")
    except Exception as e:
        print(f"Error: {e}")


def demo_full_pipeline():
    """Demonstrate full pipeline: chunk + embed"""
    
    print("\n\n" + "=" * 80)
    print("DEMO: Full Pipeline (Chunk + Embed)")
    print("=" * 80)
    
    document = """
Multi-Agent System l√† m·ªôt h·ªá th·ªëng bao g·ªìm nhi·ªÅu agent ƒë·ªôc l·∫≠p l√†m vi·ªác c√πng nhau 
ƒë·ªÉ gi·∫£i quy·∫øt c√°c v·∫•n ƒë·ªÅ ph·ª©c t·∫°p. M·ªói agent c√≥ vai tr√≤ v√† kh·∫£ nƒÉng ri√™ng bi·ªát.

Trong h·ªá th·ªëng qu·∫£n l√Ω d·ª± √°n v·ªõi Agentic AI, ch√∫ng ta c√≥:
- Orchestrator Agent: ƒêi·ªÅu ph·ªëi c√°c agent kh√°c
- Task Agent: Ph√¢n t√≠ch c√¥ng vi·ªác v√† r·ªßi ro
- Document Agent: Tr·∫£ l·ªùi c√¢u h·ªèi t·ª´ t√†i li·ªáu
- Board Agent: T·∫°o bi·ªÉu ƒë·ªì tr·ª±c quan
"""
    
    print(f"Document: {len(document)} characters\n")
    
    try:
        # Step 1: Chunk
        print("Step 1: Chunking...")
        chunker = ChunkerFactory.create_chunker(
            method="paragraph",
            chunk_size=200,
            overlap=30
        )
        chunks = chunker.chunk(document)
        print(f"  ‚Üí Generated {len(chunks)} chunks")
        
        # Step 2: Embed
        print("\nStep 2: Embedding...")
        embedder = EmbeddingFactory.create_embedder(
            provider="huggingface",
            model_name="sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2",
            device="cpu"
        )
        
        chunk_texts = [chunk.text for chunk in chunks]
        result = embedder.embed_batch(chunk_texts)
        print(f"  ‚Üí Generated {len(result)} embeddings")
        print(f"  ‚Üí Dimensions: {result.dimensions}")
        
        # Step 3: Show results
        print("\nResults:")
        for i, (chunk, embedding) in enumerate(zip(chunks, result.embeddings)):
            print(f"\n  Chunk {i}:")
            print(f"    Text: {chunk.text[:80]}...")
            print(f"    Embedding shape: {embedding.shape}")
            print(f"    Token count: {chunk.token_count}")
        
        print("\n‚úÖ Pipeline completed successfully!")
        
    except ImportError:
        print("‚ö†Ô∏è  Required packages not installed")
        print("   Install with: pip install sentence-transformers")
    except Exception as e:
        print(f"‚ùå Error: {e}")


def main():
    """Run all demos"""
    
    print("\n" + "üöÄ " * 20)
    print("CHUNKING & EMBEDDING DEMO")
    print("üöÄ " * 20)
    
    # Run demos
    demo_chunking()
    demo_embedding()
    demo_full_pipeline()
    
    print("\n" + "=" * 80)
    print("Demo completed!")
    print("=" * 80)


if __name__ == "__main__":
    main()
