data_preprocessing:
  parsing:
    # Parser selection: pymupdf (fast, lightweight) or docling (advanced features)
    default_parser: "pymupdf"              # Default parser for PDFs: pymupdf | docling
    encoding: "utf-8"
    
    # PyMuPDF configuration (fast PDF parser - default)
    pymupdf:
      extract_images: false                # Extract images from PDFs
      preserve_layout: true                # Preserve text layout
      max_file_size_mb: 500                # Maximum file size to process
    
    # Docling configuration (universal document parser with advanced features)
    docling:
      ocr_enabled: true                    # Enable OCR for scanned documents and images
      table_extraction: true               # Extract tables from documents
      output_format: "markdown"            # Output format: markdown, text, or html
      max_file_size_mb: 50                # Maximum file size to process
    
    # Markdown configuration (for user-written documents)
    markdown:
      extensions:                          # Python-Markdown extensions
        - "extra"                          # Extra features (abbr, attr_list, def_list, etc.)
        - "meta"                           # Metadata support
        - "toc"                            # Table of contents
        - "tables"                         # Table support
        - "fenced_code"                    # Code blocks with syntax highlighting
      parse_frontmatter: true              # Extract YAML frontmatter metadata
      preserve_formatting: true            # Keep markdown formatting in output
    
    # Text processing options
    preprocessing:
      remove_stopwords: false              # Remove Vietnamese/English stopwords
      lowercase: false                     # Convert to lowercase
      remove_urls: false                   # Remove URLs from text
      remove_emails: false                 # Remove email addresses
      min_text_length: 50                  # Minimum text length to process (chars)
    
  chunking:
    method: "paragraph"
    overlap: 50
    chunk_size: 2000
  embedding:
    provider: naver  # Changed from huggingface to naver
    huggingface:
      model: "Qwen/Qwen3-Embedding-0.6B"
      batch_size: 16
    naver:
      model: "bge-m3"  # Naver CLOVA embedding model (1024 dim)
      batch_size: 16

llm:
  # Provider mặc định
  default_provider: naver
  
  # Cấu hình cho từng provider
  providers:
    naver:
      model: HCX-007
      temperature: 0.1
      max_tokens: 2000
      system_prompt: Bạn là một trợ lý AI hữu ích và thân thiện, chuyên nói tiếng Việt.
    
    openai:
      model: gpt-4o-mini
      temperature: 0.1
      max_tokens: 2000
      system_prompt: You are a helpful and friendly DevHolic AI assistant.
    
    cerebras:
      model: qwen-3-32b
      temperature: 0.1
      max_tokens: 2000
      system_prompt: You are a helpful and friendly DevHolic AI assistant.
    
    gemini:
      model: gemini-2.0-flash-lite
      temperature: 0.1
      max_tokens: 2000
      system_prompt: You are a helpful and friendly DevHolic AI assistant.
  
  # Backward compatibility
  naver_llm:
    chat_model:
      name: HCX-007
      temperature: 0.1
      max_tokens: 2000
      system_prompt: Bạn là một trợ lý AI hữu ích và thân thiện, chuyên nói tiếng Việt.

retrieval:
  vector_similarity:
    enabled: true
    top_k: 10
    score_threshold: 0.5
  bm25:
    enabled: false           # Feature flag - DISABLED by default during development
    tokenizer:
      vietnamese:
        library: underthesea  # Vietnamese tokenizer: underthesea | pyvi
        stopwords: true         # Remove Vietnamese stopwords
      english:
        library: nltk         # English tokenizer: nltk | spacy
        stopwords: true         # Remove English stopwords
    parameters:
      k1: 1.5                # Term frequency saturation (1.2-2.0 typical range)
      b: 0.75                # Length normalization (0.0=none, 1.0=full)
    indexing:
      batch_size: 1000       # Number of chunks to process per batch
      parallel_catalogs: 4   # Number of catalogs to index in parallel      
  reranker:
    enabled: true          # Enable BM25 reranking after vector similarity search
    top_k: 10              # Number of top results from vector search to rerank
    model: BAAI/bge-reranker-v2-m3
  rrf: